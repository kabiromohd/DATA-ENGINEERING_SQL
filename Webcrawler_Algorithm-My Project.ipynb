{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8483a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import \n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import psycopg2 as pg \n",
    "\n",
    "\n",
    "\n",
    "def linkGet():\n",
    "    links_data = []\n",
    "    data_frame = []\n",
    "    for x in range(1,14):\n",
    "        ton = urlopen(f'https://pureportal.coventry.ac.uk/en/organisations/school-of-economics-finance-and-accounting/publications/?page={x}')\n",
    "        read_ton = soup(ton.read())\n",
    "\n",
    "        for link in read_ton.findAll(\"a\"):\n",
    "            if \"href\" in link.attrs:\n",
    "                links_val = link.attrs[\"href\"]\n",
    "                if links_val[:len(\"https\")] == \"https\":\n",
    "                    doc_array = links_val.split(\"/\")\n",
    "                    if len(doc_array) == 6:\n",
    "                        if \"organisations\" not in doc_array:\n",
    "                            links_data.append(links_val)\n",
    "        new_lst = []\n",
    "        for i in links_data:\n",
    "            i_val = i.split(\"/\")\n",
    "            for n in range(0, len(i_val)):\n",
    "                if i_val[n] == \"publications\":\n",
    "                        new_lst.append([])\n",
    "            new_lst[-1].append(i)\n",
    "\n",
    "        for i in new_lst:\n",
    "            data = []\n",
    "            for n in i:\n",
    "                data.append(n)\n",
    "            data_frame.append(data)\n",
    "\n",
    "    df = pd.DataFrame(data_frame)\n",
    "    df.columns = [\"publication_link\", \"Author_profile\", \"co-author_Profile\", \"co_author_profile2\"]\n",
    "    df.head()\n",
    "    print(\"Get Worked\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def link2Get():\n",
    "    data_frame = []\n",
    "    links_books = []\n",
    "    for x in range(1,14):\n",
    "        ton = urlopen(f'https://pureportal.coventry.ac.uk/en/organisations/school-of-economics-finance-and-accounting/publications/?page={x}')\n",
    "        read_ton = soup(ton.read())\n",
    "        \n",
    "        for link in read_ton.findAll(\"a\"):\n",
    "            if \"href\" in link.attrs:\n",
    "                links_val = link.attrs[\"href\"]\n",
    "                if links_val[:len(\"https\")] == \"https\":\n",
    "                    doc_array = links_val.split(\"/\")\n",
    "                    if len(doc_array) == 6:\n",
    "                        if \"organisations\" not in doc_array:\n",
    "                            for k in doc_array[4:]:\n",
    "                                links_books.append(k)\n",
    "\n",
    "\n",
    "        new_lst=[]\n",
    "        target = \"publications\"\n",
    "        for i in links_books:\n",
    "            if i == target:\n",
    "                new_lst.append([])\n",
    "            new_lst[-1].append(i)\n",
    "\n",
    "\n",
    "        data_frame = []\n",
    "        for i in new_lst:\n",
    "            data = []\n",
    "            for n in i:\n",
    "                data.append(n)\n",
    "            data_frame.append(data)\n",
    "\n",
    "\n",
    "    df_d = pd.DataFrame(data_frame)\n",
    "    df_d.columns = [\"publication_index\", \"Publication\", \"person_value\", \"Author\", \"person_value2\",\n",
    "                    \"Co-author\", \"person_name3\", \"Co-author2\"]\n",
    "\n",
    "\n",
    "    data_df = df_d.drop([\"publication_index\", \"person_value\", \"person_value2\", \"person_name3\"], axis=1)\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def saveScrapDate(final_output):\n",
    "    #Save Scrap data as Json file in path to be read\n",
    "    json_output = r'C:\\Users\\USER\\Desktop\\WORKPLACE\\Dataset\\DataforUpload.json'\n",
    "    output = final_output.to_json(json_output, indent = 1, orient = 'records')\n",
    "    return json_output\n",
    "\n",
    "\n",
    "def SendDatatoPostGre(host, database, user, password):\n",
    "    #####Sending Data to PostgresL\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = pg.connect(\n",
    "        host = host,\n",
    "        database = database,\n",
    "        user = user,\n",
    "        password = password\n",
    "    )\n",
    "\n",
    "    # Create a cursor\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Load the DataFrame from a file or some other source\n",
    "    df = pd.read_json(json_output)  #====> Json\n",
    "\n",
    "    # Convert the DataFrame to a list of tuples\n",
    "    data = [tuple(x) for x in df.values]\n",
    "\n",
    "    # Create the table\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE TestTable(\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        Publication text,\n",
    "        Author text,\n",
    "        CoAuthorI text,\n",
    "        CoAauthorII text,\n",
    "        publication_link varchar,\n",
    "        Author_profile text,\n",
    "        co_author_Profile text,\n",
    "        co_author_profile2 text\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Insert the data into the table\n",
    "    cur.executemany(\"\"\"\n",
    "    INSERT INTO TestTable(Publication, Author, CoAuthorI, CoAauthorII, publication_link,\n",
    "           Author_profile, co_author_Profile, co_author_profile2)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", data)\n",
    "\n",
    "    # Commit the changes\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return\n",
    "\n",
    "def SearchforAuthor(final_output):\n",
    "    ##### search authors or co-authors by name ######\n",
    "    search_value = input(\"enter authors or co-authors name: \").lower()\n",
    "    array_values = final_output.columns[1:4]\n",
    "    for i in array_values:\n",
    "        ss = final_output[final_output[i] == search_value]\n",
    "        print(ss)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb2b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Body of Project\n",
    "\n",
    "dx = linkGet()\n",
    "dy = link2Get()\n",
    "\n",
    "final_output = pd.concat([dy, dx], axis=1)\n",
    "final_output.head(10)\n",
    "\n",
    "final_output.columns = ['Publication', 'Author', 'CoAuthorI', 'CoAauthorII', 'publication_link',\n",
    "       'Author_profile', 'co_author_Profile', 'co_author_profile2']\n",
    "\n",
    "saveScrapDate(final_output)\n",
    "\n",
    "SearchforAuthor(final_output)\n",
    "\n",
    "host = \"localhost\",\n",
    "database = \"postgres\",\n",
    "user = \"postgres\",\n",
    "password = input(\"ENTER POSTGRESQL PASSWORD: \")\n",
    "\n",
    "SendDatatoPostGre(host, database, user, password, json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411be07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
